A multi-threaded web scraper in C that fetches data from multiple URLs in parallel. The scraper takes URLs as arguments and downloads their content and saves them into html files. 

**USAGE**

Clone the repository onto your machine and `cd` into `scraper/` 

Compile `scraper.c`

Run the executable file created passing the URLs as arguments:

`./scraper <url_1> <url_2>....<url_n>`

Find the downloaded html files in your directory.
